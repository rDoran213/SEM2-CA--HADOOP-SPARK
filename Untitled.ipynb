{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc72ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44092e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('secrets.json', 'r') as file:\n",
    "    secret_data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7886b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_start = \"2020-01-01\"\n",
    "\n",
    "api_key_arg = \"&api_key=\" + secret_data.get(\"api_key\")\n",
    "api_start_arg = \"&start=\" + api_data_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9917eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###data_endpoint = \"https://api.eia.gov/v2/electricity/rto/daily-region-sub-ba-data/data/?frequency=daily&data[0]=value&start=2025-03-15&sort[0][column]=period&sort[0][direction]=desc&offset=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_endpoint = \"https://api.eia.gov/v2/electricity/rto/daily-region-data/data/?frequency=daily&data[0]=value&facets[respondent][]=NY&facets[timezone][]=Eastern&facets[type][]=D&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6532a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd595db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response = requests.get(data_endpoint+api_start_arg+api_key_arg)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"request succeeded\")\n",
    "\n",
    "else:\n",
    "    print(f\"request failed, code:  {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.get(\"response\").get(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4188b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m raw_df = \u001b[43mpd\u001b[49m.DataFrame(data.get(\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m).get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#raw_df\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m##df = pd.DataFrame(data.get(\"data\"))\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(data.get(\"response\").get(\"data\"))\n",
    "#raw_df\n",
    "##df = pd.DataFrame(data.get(\"data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0aac7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mraw_df\u001b[49m.to_csv(\u001b[33m'\u001b[39m\u001b[33mtest-data.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_df' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df.to_csv('test-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf139802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 20:38:18 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/03/31 20:38:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , period, respondent, respondent-name, type, type-name, timezone, timezone-description, value, value-units\n",
      " Schema: _c0, period, respondent, respondent-name, type, type-name, timezone, timezone-description, value, value-units\n",
      "Expected: _c0 but found: \n",
      "CSV file: hdfs://localhost:9000/testdata/test-data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---------------+----+---------+--------+--------------------+------+-------------+\n",
      "|_c0|    period|respondent|respondent-name|type|type-name|timezone|timezone-description| value|  value-units|\n",
      "+---+----------+----------+---------------+----+---------+--------+--------------------+------+-------------+\n",
      "|  0|2025-03-30|        NY|       New York|   D|   Demand| Eastern|             Eastern|360251|megawatthours|\n",
      "|  1|2025-03-29|        NY|       New York|   D|   Demand| Eastern|             Eastern|356584|megawatthours|\n",
      "|  2|2025-03-28|        NY|       New York|   D|   Demand| Eastern|             Eastern|373815|megawatthours|\n",
      "|  3|2025-03-27|        NY|       New York|   D|   Demand| Eastern|             Eastern|371568|megawatthours|\n",
      "|  4|2025-03-26|        NY|       New York|   D|   Demand| Eastern|             Eastern|383131|megawatthours|\n",
      "|  5|2025-03-25|        NY|       New York|   D|   Demand| Eastern|             Eastern|378674|megawatthours|\n",
      "|  6|2025-03-24|        NY|       New York|   D|   Demand| Eastern|             Eastern|398827|megawatthours|\n",
      "|  7|2025-03-23|        NY|       New York|   D|   Demand| Eastern|             Eastern|351612|megawatthours|\n",
      "|  8|2025-03-22|        NY|       New York|   D|   Demand| Eastern|             Eastern|354942|megawatthours|\n",
      "|  9|2025-03-21|        NY|       New York|   D|   Demand| Eastern|             Eastern|360106|megawatthours|\n",
      "| 10|2025-03-20|        NY|       New York|   D|   Demand| Eastern|             Eastern|365904|megawatthours|\n",
      "| 11|2025-03-19|        NY|       New York|   D|   Demand| Eastern|             Eastern|354325|megawatthours|\n",
      "| 12|2025-03-18|        NY|       New York|   D|   Demand| Eastern|             Eastern|367109|megawatthours|\n",
      "| 13|2025-03-17|        NY|       New York|   D|   Demand| Eastern|             Eastern|383316|megawatthours|\n",
      "| 14|2025-03-16|        NY|       New York|   D|   Demand| Eastern|             Eastern|350585|megawatthours|\n",
      "| 15|2025-03-15|        NY|       New York|   D|   Demand| Eastern|             Eastern|353508|megawatthours|\n",
      "| 16|2025-03-14|        NY|       New York|   D|   Demand| Eastern|             Eastern|362794|megawatthours|\n",
      "| 17|2025-03-13|        NY|       New York|   D|   Demand| Eastern|             Eastern|374367|megawatthours|\n",
      "| 18|2025-03-12|        NY|       New York|   D|   Demand| Eastern|             Eastern|380035|megawatthours|\n",
      "| 19|2025-03-11|        NY|       New York|   D|   Demand| Eastern|             Eastern|360839|megawatthours|\n",
      "+---+----------+----------+---------------+----+---------+--------+--------------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "os.system(\"hdfs dfs -put -f ./test-data.csv /testdata/\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Power Demand Tracker\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_spark = spark.read.csv('hdfs:///testdata/test-data.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac1186ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b191230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "filtered_spark_df = df_spark.select(\n",
    "    col(\"period\").alias(\"Date\"),\n",
    "    col(\"value\").alias(\"MWh\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbb85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_spark_df = df_spark.select('period', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08da28e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      Date|   MWh|\n",
      "+----------+------+\n",
      "|2025-03-30|360251|\n",
      "|2025-03-29|356584|\n",
      "|2025-03-28|373815|\n",
      "|2025-03-27|371568|\n",
      "|2025-03-26|383131|\n",
      "|2025-03-25|378674|\n",
      "|2025-03-24|398827|\n",
      "|2025-03-23|351612|\n",
      "|2025-03-22|354942|\n",
      "|2025-03-21|360106|\n",
      "|2025-03-20|365904|\n",
      "|2025-03-19|354325|\n",
      "|2025-03-18|367109|\n",
      "|2025-03-17|383316|\n",
      "|2025-03-16|350585|\n",
      "|2025-03-15|353508|\n",
      "|2025-03-14|362794|\n",
      "|2025-03-13|374367|\n",
      "|2025-03-12|380035|\n",
      "|2025-03-11|360839|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96237ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = raw_df[['period', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c3ceb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995e6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40103052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----+\n",
      "|      Date|   MWh|Day|Month|\n",
      "+----------+------+---+-----+\n",
      "|2025-03-30|360251|  1|    3|\n",
      "|2025-03-29|356584|  7|    3|\n",
      "|2025-03-28|373815|  6|    3|\n",
      "|2025-03-27|371568|  5|    3|\n",
      "|2025-03-26|383131|  4|    3|\n",
      "|2025-03-25|378674|  3|    3|\n",
      "|2025-03-24|398827|  2|    3|\n",
      "|2025-03-23|351612|  1|    3|\n",
      "|2025-03-22|354942|  7|    3|\n",
      "|2025-03-21|360106|  6|    3|\n",
      "|2025-03-20|365904|  5|    3|\n",
      "|2025-03-19|354325|  4|    3|\n",
      "|2025-03-18|367109|  3|    3|\n",
      "|2025-03-17|383316|  2|    3|\n",
      "|2025-03-16|350585|  1|    3|\n",
      "|2025-03-15|353508|  7|    3|\n",
      "|2025-03-14|362794|  6|    3|\n",
      "|2025-03-13|374367|  5|    3|\n",
      "|2025-03-12|380035|  4|    3|\n",
      "|2025-03-11|360839|  3|    3|\n",
      "+----------+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = filtered_spark_df.withColumn(\"Day\", F.dayofweek(\"Date\"))\n",
    "features_df = features_df.withColumn(\"Month\", F.month(\"Date\"))\n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af5aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Writes back data to Hadoop\n",
    "#features_df.write.option(\"header\", True).mode(\"overwrite\").csv(\"hdfs:////user/hduser/unscaled-data\")\n",
    "\n",
    "features_df.write.mode(\"overwrite\").option(\"header\", True).csv(\"hdfs:///unscaled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4811196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_df.coalesce(1).write.option(\"header\", True).mode(\"overwrite\").csv(\"/.unscaled-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2b13dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_df.write.csv(os.getcwd()+\"/newtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f32622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-----+\n",
      "|      Date|   MWh|Day|Month|\n",
      "+----------+------+---+-----+\n",
      "|2025-03-30|360251|  1|    3|\n",
      "|2025-03-29|356584|  7|    3|\n",
      "|2025-03-28|373815|  6|    3|\n",
      "|2025-03-27|371568|  5|    3|\n",
      "|2025-03-26|383131|  4|    3|\n",
      "|2025-03-25|378674|  3|    3|\n",
      "|2025-03-24|398827|  2|    3|\n",
      "|2025-03-23|351612|  1|    3|\n",
      "|2025-03-22|354942|  7|    3|\n",
      "|2025-03-21|360106|  6|    3|\n",
      "|2025-03-20|365904|  5|    3|\n",
      "|2025-03-19|354325|  4|    3|\n",
      "|2025-03-18|367109|  3|    3|\n",
      "|2025-03-17|383316|  2|    3|\n",
      "|2025-03-16|350585|  1|    3|\n",
      "|2025-03-15|353508|  7|    3|\n",
      "|2025-03-14|362794|  6|    3|\n",
      "|2025-03-13|374367|  5|    3|\n",
      "|2025-03-12|380035|  4|    3|\n",
      "|2025-03-11|360839|  3|    3|\n",
      "+----------+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_test = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"hdfs:///unscaled/\")\n",
    "df_spark_test.show()\n",
    "\n",
    "\n",
    "##hdfs dfs -getmerge /unscaled/ ./unscaled-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ad4dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47e04593",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_df = features_df.select(\"Date\", \"MWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d10b78da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"MWh\"], outputCol=\"feature_MWh\")\n",
    "df_vec = assembler.transform(RNN_df)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"feature_MWh\", outputCol=\"scaled_MWh\")\n",
    "scaler_model = scaler.fit(df_vec)\n",
    "scaled_df = scaler_model.transform(df_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fa924be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+--------------------+\n",
      "|      Date|   MWh|feature_MWh|          scaled_MWh|\n",
      "+----------+------+-----------+--------------------+\n",
      "|2025-03-30|360251| [360251.0]|[0.16638138061417...|\n",
      "|2025-03-29|356584| [356584.0]|[0.15467081395942...|\n",
      "|2025-03-28|373815| [373815.0]|[0.20969802258443...|\n",
      "|2025-03-27|371568| [371568.0]|[0.20252222676408...|\n",
      "|2025-03-26|383131| [383131.0]|[0.23944867405855...|\n",
      "|2025-03-25|378674| [378674.0]|[0.22521524193960...|\n",
      "|2025-03-24|398827| [398827.0]|[0.28957385928159...|\n",
      "|2025-03-23|351612| [351612.0]|[0.13879272903786...|\n",
      "|2025-03-22|354942| [354942.0]|[0.14942708599458...|\n",
      "|2025-03-21|360106| [360106.0]|[0.16591832302897...|\n",
      "|2025-03-20|365904| [365904.0]|[0.18443423943590...|\n",
      "|2025-03-19|354325| [354325.0]|[0.1474566961320321]|\n",
      "|2025-03-18|367109| [367109.0]| [0.188282407643963]|\n",
      "|2025-03-17|383316| [383316.0]|[0.2400394716672628]|\n",
      "|2025-03-16|350585| [350585.0]|[0.13551300393439...|\n",
      "|2025-03-15|353508| [353508.0]|[0.14484760615195...|\n",
      "|2025-03-14|362794| [362794.0]|[0.1745024526084513]|\n",
      "|2025-03-13|374367| [374367.0]|[0.21146083490879...|\n",
      "|2025-03-12|380035| [380035.0]|[0.22956159623933...|\n",
      "|2025-03-11|360839| [360839.0]|[0.16825915895968...|\n",
      "+----------+------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98421c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------------+\n",
      "|      Date|   MWh|         scaled_MWh|\n",
      "+----------+------+-------------------+\n",
      "|2025-03-30|360251|0.16638138061417404|\n",
      "|2025-03-29|356584|0.15467081395942978|\n",
      "|2025-03-28|373815|0.20969802258443618|\n",
      "|2025-03-27|371568|0.20252222676408974|\n",
      "|2025-03-26|383131|0.23944867405855605|\n",
      "|2025-03-25|378674|0.22521524193960452|\n",
      "|2025-03-24|398827|0.28957385928159013|\n",
      "|2025-03-23|351612|0.13879272903786216|\n",
      "|2025-03-22|354942|0.14942708599458382|\n",
      "|2025-03-21|360106|0.16591832302897144|\n",
      "|2025-03-20|365904|0.18443423943590007|\n",
      "|2025-03-19|354325| 0.1474566961320321|\n",
      "|2025-03-18|367109|  0.188282407643963|\n",
      "|2025-03-17|383316| 0.2400394716672628|\n",
      "|2025-03-16|350585|0.13551300393439272|\n",
      "|2025-03-15|353508|0.14484760615195955|\n",
      "|2025-03-14|362794| 0.1745024526084513|\n",
      "|2025-03-13|374367|0.21146083490879364|\n",
      "|2025-03-12|380035|0.22956159623933373|\n",
      "|2025-03-11|360839|0.16825915895968527|\n",
      "+----------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "extract_element = udf(lambda v: float(v[0]), DoubleType())\n",
    "\n",
    "RNN_df_scaled = scaled_df.withColumn(\"scaled_MWh\", extract_element(col(\"scaled_MWh\")))\n",
    "final_RNN_df_scaled.select(\"Date\", \"MWh\", \"scaled_MWh\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a54ea",
   "metadata": {},
   "source": [
    "To install keras and tensorflow\n",
    "\n",
    "\n",
    "sudo apt update\n",
    "sudo apt install python3-venv python3-pip -y\n",
    "\n",
    "python3 -m venv keras-env\n",
    "source keras-env/bin/activate\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install keras tensorflow\n",
    "\n",
    "\n",
    "source keras-env/bin/activate\n",
    "source /home/hduser/Documents/GitHub/CCT-SEM2-CA1/SEM2-CA--HADOOP-SPARK/keras-env/bin/activate\n",
    "\n",
    "\n",
    "\n",
    "pip install jupyter ipykernel\n",
    "\n",
    "python -m ipykernel install --user --name=keras-env --display-name=\"Python (keras-env)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3aa09-3ae5-4884-86e4-3f793f2d0eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c30150-c6fd-4c59-b3bb-a86332ccc391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cb822-4c7e-4854-b11d-2c217af7aa57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fcf08-76ac-4868-b214-54426d09e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300853a6-7cbb-4dee-b349-ddb31440a617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9ed2b-5cac-49da-ba49-19b85ac35d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da0f1d-fa2d-4852-b281-3becb0335fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfe179-25f6-4355-baf0-6174e0700e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc7552-c982-4c01-9ffe-0e63af8087ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ceae2b-2f96-44d0-b9eb-d56ccbd54f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459f69c-46ea-4a56-b3fe-243c0327571a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f600a4-b503-4d00-b578-a1fc25b119e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e0ebc-c2b6-4d84-b61b-82dfbe65c8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395ac39-bdc1-4545-b41e-43eff4046160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260a448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session, Pipeline, Functions, and Metrics\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##pip install keras tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18dfb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras / Deep Learning\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras import optimizers, regularizers\n",
    "#from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elephas for Deep Learning on Spark\n",
    "from elephas.ml_model import ElephasEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa668f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87d21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b381d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f8b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "#df['period'] = pd.to_datetime(df['period'])\n",
    "#df.set_index('period', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef875c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#df.plot(ax=ax)\n",
    "\n",
    "#ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "\n",
    "#ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7467312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca302ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa096091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b896346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "531f117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = test_df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a2a52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = scaler.fit_transform(training_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "355f2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler.fit(df)\n",
    "#scaled_data = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec5ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e537ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c63103ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_test_df = pd.DataFrame(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39ee5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc99cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904caad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ca69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12866841",
   "metadata": {},
   "source": [
    "Save Data to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83afca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save df as csv\n",
    "\n",
    "##df.to_csv('test-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6eb0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload to Hadoop\n",
    "\n",
    "#import os\n",
    "\n",
    "#os.system(\"hdfs dfs -put -f ./test-data.csv /testdata/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba3bb2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f6743bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "#import os\n",
    "\n",
    "#os.system(\"hdfs dfs -put -f ./test-data.csv /testdata/\")\n",
    "\n",
    "\n",
    "#park = SparkSession.builder \\\n",
    "   # .appName(\"Power Demand Tracker\") \\\n",
    " #  .getOrCreate()\n",
    "\n",
    "#df_spark = spark.read.csv('hdfs:///testdata/test-data.csv', header=True, inferSchema=True)\n",
    "\n",
    "#df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c34aa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d6600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e56a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3406f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras-env)",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
